\chapter{Data Stream Processing}
\label{chap:data_stream_processing}

With the advent of \emph{Big Data} era, large amount of data are being generated 
by the companies from their infrastructure; from the IoT sensors to the events 
generated by the customers using their online services. The data that 
are generated are by nature \emph{unbounded} and infinite since as long 
as the infrastructure is working, new data will be continuously generated. 

For example, the healthcare industry has also been transitioning to 
adopt the approach of data-drive diagnostics methods~\cite{hospital_diagnosis}. 
This transition is caused by the need to keep up with the increase in the amount 
of physiological data generated by the monitoring sensors attached to the 
patients~\cite{hospital_data_monitoring}. These physiological data are generated 
periodically at regular intervals in a streaming manner. 

As a consequence of the large volume and continuous data generation, there is a need for 
the companies to be able to process these unbounded data streams. 
Stream processing engines are equipped to handle such unbounded data and exists in 
the industry today (e.g. Apache Flink~\cite{flink} and 
Apache Spark streaming~\cite{spark_streaming}). Main features of these stream 
processing engines are their ability to 
\renewcommand{\labelenumi}{(\roman{enumi})}
\begin{enumerate*}
    \item scale horizontally, 
    \item process records individually as they arrive, and
    \item process or analyse the data in real time.
\end{enumerate*}

In Chapter~\ref{chap:data_stream_processing}, we will dive into details of 
on the characteristics of data streams and also elaborate on the 
various state-of-the-art frameworks in use by the industries. 


\section{Characteristics of Data Streams}

Traditional Big Data processing techniques use large volume datasets, which are bounded,
stored on storage medium before the processing.