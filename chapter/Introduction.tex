\chapter{Introduction}
\label{chap:intro}

A large volume of data is generated daily on the Web in a variety of domains. These
data are often structured according to an organization's specific needs or formats: Leading to
a difficulty in integrating the data across the different applications.
These generated data might have to be associated with archival data, also of heterogeneous formats,
to provide a coherent view required by analysis tasks. Heterogeneous Web data formats, such as CSV or HTML, are not explicitly
defined to enable linking entities in one document to other related entities in external documents.

Based on W3C standard, semantic data formats such as RDF triples~\cite{intro_rdf}, are a solution to
this particular problem by enriching the data with knowledge and association across
different domains, through the use of common ontologies. RDF triples also form the basic building blocks of knowledge graphs.
Knowledge graphs are extensively used in social networks like Facebook\cite{facebook_linked_data}, IoT devices\cite{graph_of_things} and especially with Google's search
engine\cite{google_kg}, it enables machines to understand the data and perform complex automated processing
using the knowledge graphs. 

Considering the aforementioned scenarios, there is a need to transform these non-RDF data to RDF compliant formats on the fly while
new data are being generated. Furthermore, we would also like to apply stream operators on the input tuples
before transforming, to enhance the enrichment of the data.

There exists state-of-the-art techniques to solve the task of consolidating heterogeneous data
and transforming them to an RDF compliant format. In this thesis, we will focus on one such format called TURTLE~\cite{turtle_syntax}.
These RDF transformation engines can be categorized into two major categories based on the type of input
which they consume; bounded and unbounded data input. Since we are focussing on the generation of RDF data
in a streaming environment, the class of RDF transformation engines on unbounded data will be of interest to our study.

Some engines support traditional stream operators like joins and aggregations. However, they do not consider
the characteristics of the streaming sources such as velocity and time-correlations between the different
input streams. This leads to a decline in the quality of the generated RDF triples. Moreover,
due to the nature of the infinite, continuous and real-time changing data of the streaming environment,
these operators have to be applied in the context of windows over a subset of the incoming data.
Clearly, with these restrictions and characteristics of the streaming sources, we need an adaptive approach
to applying these operators in windows for the data transformation engines.
